{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## How to Define and Use the Generator Model\n", 
        "The generator model is responsible for creating new, fake but plausible images of handwritten\n", 
        "digits. It does this by taking a point from the latent space as input and outputting a square7.4. How to Define and Use the Generator Model 106\n", 
        "grayscale image. The latent space is an arbitrarily defined vector space of Gaussian-distributed\n", 
        "values, e.g. 100 dimensions. It has no meaning, but by drawing points from this space randomly\n", 
        "and providing them to the generator model during training, the generator model will assign\n", 
        "meaning to the latent points. At the end of training, the latent vector space represents a\n", 
        "compressed representation of the output space, MNIST images, that only the generator knows\n", 
        "how to turn into plausible MNIST images.\n", 
        "\n", 
        "\u277c Inputs: Point in latent space, e.g. a 100 element vector of Gaussian random numbers.\n", 
        "\u277c Outputs: Two-dimensional square grayscale image of 28 \u00d7 28 pixels with pixel values in\n", 
        "[0,1].\n", 
        "\n", 
        "We don\u2019t have to use a 100 element vector as input; it is a round number and widely used,\n", 
        "but I would expect that 10, 50, or 500 would work just as well. Developing a generator model\n", 
        "requires that we transform a vector from the latent space with, 100 dimensions to a 2D array\n", 
        "with 28\u00d728 or 784 values. There are a number of ways to achieve this but there is one approach\n", 
        "that has proven effective at deep convolutional generative adversarial networks. It involves two\n", 
        "main elements. The first is a Dense layer as the first hidden layer that has enough nodes to\n", 
        "represent a low-resolution version of the output image. Specifically, an image half the size (one\n", 
        "quarter the area) of the output image would be 14 \u00d7 14 or 196 nodes, and an image one quarter\n", 
        "the size (one eighth the area) would be 7 \u00d7 7 or 49 nodes.\n", 
        "\n", 
        "We don\u2019t just want one low-resolution version of the image; we want many parallel versions\n", 
        "or interpretations of the input. This is a pattern in convolutional neural networks where we\n", 
        "have many parallel filters resulting in multiple parallel activation maps, called feature maps,\n", 
        "with different interpretations of the input. We want the same thing in reverse: many parallel\n", 
        "versions of our output with different learned features that can be collapsed in the output layer\n", 
        "into a final image. The model needs space to invent, create, or generate. Therefore, the first\n", 
        "hidden layer, the Dense layer needs enough nodes for multiple low-resolution versions of our\n", 
        "output image, such as 128."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of defining the generator model\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Reshape\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Conv2DTranspose\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# define the standalone generator model\n", 
        "def define_generator(latent_dim):\n", 
        "\tmodel = Sequential()\n", 
        "\t# foundation for 7x7 image\n", 
        "\tn_nodes = 128 * 7 * 7\n", 
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\tmodel.add(Reshape((7, 7, 128)))\n", 
        "\t# upsample to 14x14\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# upsample to 28x28\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\tmodel.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n", 
        "\treturn model\n", 
        "\n", 
        "# define the size of the latent space\n", 
        "latent_dim = 100\n", 
        "# define the generator model\n", 
        "model = define_generator(latent_dim)\n", 
        "# summarize the model\n", 
        "model.summary()\n", 
        "# plot the model\n", 
        "plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('generator_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}