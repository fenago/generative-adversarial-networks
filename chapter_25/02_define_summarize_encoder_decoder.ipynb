{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## How to Implement the CycleGAN Generator Model\n", 
        "The CycleGAN Generator model takes an image as input and generates a translated image as\n", 
        "output. The model uses a sequence of downsampling convolutional blocks to encode the input\n", 
        "image, a number of residual network (ResNet) convolutional blocks to transform the image, and\n", 
        "a number of upsampling convolutional blocks to generate the output image.\n", 
        "\n", 
        "Let c7s1-k denote a 7 \u00d7 7 Convolution-InstanceNormReLU layer with k filters and\n", 
        "stride 1. dk denotes a 3 \u00d7 3 Convolution-InstanceNorm-ReLU layer with k filters\n", 
        "and stride 2. Reflection padding was used to reduce artifacts. Rk denotes a residual\n", 
        "block that contains two 3 \u00d7 3 convolutional layers with the same number of filters on\n", 
        "both layer. uk denotes a 3 \u00d7 3 fractional-strided-ConvolutionInstanceNorm-ReLU\n", 
        "layer with k filters and stride 1 2.\n", 
        "\n", 
        "First, we need a function to define the ResNet blocks. These are blocks comprised of two\n", 
        "3 \u00d7 3 CNN layers where the input to the block is concatenated to the output of the block,\n", 
        "channel-wise. This is implemented in the resnet block() function that creates two ConvInstanceNorm blocks with 3 \u00d7 3 filters and 1 \u00d7 1 stride and without a ReLU activation after the\n", 
        "second block, matching the official Torch implementation in the build conv block() function.\n", 
        "Same padding is used instead of reflection padded recommended in the paper for simplicity.\n", 
        "# generator a resnet block"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of an encoder-decoder generator for the cyclegan\n", 
        "from keras.models import Model\n", 
        "from keras.models import Input\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Conv2DTranspose\n", 
        "from keras.layers import Activation\n", 
        "from keras.initializers import RandomNormal\n", 
        "from keras.layers import Concatenate\n", 
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# generator a resnet block\n", 
        "def resnet_block(n_filters, input_layer):\n", 
        "\t# weight initialization\n", 
        "\tinit = RandomNormal(stddev=0.02)\n", 
        "\t# first layer convolutional layer\n", 
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# second convolutional layer\n", 
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\t# concatenate merge channel-wise with input layer\n", 
        "\tg = Concatenate()([g, input_layer])\n", 
        "\treturn g\n", 
        "\n", 
        "# define the standalone generator model\n", 
        "def define_generator(image_shape=(256,256,3), n_resnet=9):\n", 
        "\t# weight initialization\n", 
        "\tinit = RandomNormal(stddev=0.02)\n", 
        "\t# image input\n", 
        "\tin_image = Input(shape=image_shape)\n", 
        "\t# c7s1-64\n", 
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# d128\n", 
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# d256\n", 
        "\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# R256\n", 
        "\tfor _ in range(n_resnet):\n", 
        "\t\tg = resnet_block(256, g)\n", 
        "\t# u128\n", 
        "\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# u64\n", 
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# c7s1-3\n", 
        "\tg = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tout_image = Activation('tanh')(g)\n", 
        "\t# define model\n", 
        "\tmodel = Model(in_image, out_image)\n", 
        "\treturn model\n", 
        "\n", 
        "# create the model\n", 
        "model = define_generator()\n", 
        "# summarize the model\n", 
        "model.summary()\n", 
        "# plot the model\n", 
        "plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('generator_model_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}