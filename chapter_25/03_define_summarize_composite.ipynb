{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## How to Implement Composite Models and Loss\n", 
        "The generator models are not updated directly. Instead, the generator models are updated via\n", 
        "composite models. An update to each generator model involves changes to the model weights\n", 
        "based on four concerns:\n", 
        "- Adversarial loss (L2 or mean squared error).\n", 
        "- Identity loss (L1 or mean absolute error).\n", 
        "- Forward cycle loss (L1 or mean absolute error).\n", 
        "- Backward cycle loss (L1 or mean absolute error).\n", 
        "The adversarial loss is the standard approach for updating the generator via the discriminator,\n", 
        "although in this case, the least squares loss function is used instead of the negative log likelihood\n", 
        "(e.g. binary cross-entropy). First, we can use our function to define the two generators and two\n", 
        "discriminators used in the CycleGAN."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Summarizing and plotting the composite model is a bit of a mess as it does not help to see\n", 
        "the inputs and outputs of the model clearly. We can summarize the inputs and outputs for each25.5. How to Implement Composite Models and Loss 540\n", 
        "of the composite models below. Recall that we are sharing or reusing the same set of weights if\n", 
        "a given model is used more than once in the composite model.\n", 
        "\n", 
        "- Generator-A Composite Model: Only Generator-A weights are trainable and weights\n", 
        "for other models and not trainable.\n", 
        "\t* Adversarial: Domain-B \u2192 Generator-A \u2192 Domain-A \u2192 Discriminator-A \u2192 [real/fake]\n", 
        "\t* Identity: Domain-A \u2192 Generator-A \u2192 Domain-A\n", 
        "\t* Forward Cycle: Domain-B \u2192 Generator-A \u2192 Domain-A \u2192 Generator-B \u2192 Domain-B\n", 
        "\t* Backward Cycle: Domain-A \u2192 Generator-B \u2192 Domain-B \u2192 Generator-A \u2192 Domain-A\n", 
        "\n", 
        "- Generator-B Composite Model: Only Generator-B weights are trainable and weights\n", 
        "for other models are not trainable.\n", 
        "\t* Adversarial: Domain-A \u2192 Generator-B \u2192 Domain-B \u2192 Discriminator-B \u2192 [real/fake]\n", 
        "\t* Identity: Domain-B \u2192 Generator-B \u2192 Domain-B\n", 
        "\t* Forward Cycle: Domain-A \u2192 Generator-B \u2192 Domain-B \u2192 Generator-A \u2192 Domain-A\n", 
        "\t* Backward Cycle: Domain-B \u2192 Generator-A \u2192 Domain-A \u2192 Generator-B \u2192 Domain-B\n", 
        "'''\n", 
        "\n", 
        "# example of defining composite models for training cyclegan generators\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.models import Model\n", 
        "from keras.models import Input\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Conv2DTranspose\n", 
        "from keras.layers import Activation\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.initializers import RandomNormal\n", 
        "from keras.layers import Concatenate\n", 
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n", 
        "\n", 
        "# define the discriminator model\n", 
        "def define_discriminator(image_shape):\n", 
        "\t# weight initialization\n", 
        "\tinit = RandomNormal(stddev=0.02)\n", 
        "\t# source image input\n", 
        "\tin_image = Input(shape=image_shape)\n", 
        "\t# C64\n", 
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n", 
        "\td = LeakyReLU(alpha=0.2)(d)\n", 
        "\t# C128\n", 
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n", 
        "\td = InstanceNormalization(axis=-1)(d)\n", 
        "\td = LeakyReLU(alpha=0.2)(d)\n", 
        "\t# C256\n", 
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n", 
        "\td = InstanceNormalization(axis=-1)(d)\n", 
        "\td = LeakyReLU(alpha=0.2)(d)\n", 
        "\t# C512\n", 
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n", 
        "\td = InstanceNormalization(axis=-1)(d)\n", 
        "\td = LeakyReLU(alpha=0.2)(d)\n", 
        "\t# second last output layer\n", 
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n", 
        "\td = InstanceNormalization(axis=-1)(d)\n", 
        "\td = LeakyReLU(alpha=0.2)(d)\n", 
        "\t# patch output\n", 
        "\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n", 
        "\t# define model\n", 
        "\tmodel = Model(in_image, patch_out)\n", 
        "\t# compile model\n", 
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n", 
        "\treturn model\n", 
        "\n", 
        "# generator a resnet block\n", 
        "def resnet_block(n_filters, input_layer):\n", 
        "\t# weight initialization\n", 
        "\tinit = RandomNormal(stddev=0.02)\n", 
        "\t# first layer convolutional layer\n", 
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# second convolutional layer\n", 
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\t# concatenate merge channel-wise with input layer\n", 
        "\tg = Concatenate()([g, input_layer])\n", 
        "\treturn g\n", 
        "\n", 
        "# define the standalone generator model\n", 
        "def define_generator(image_shape, n_resnet=9):\n", 
        "\t# weight initialization\n", 
        "\tinit = RandomNormal(stddev=0.02)\n", 
        "\t# image input\n", 
        "\tin_image = Input(shape=image_shape)\n", 
        "\t# c7s1-64\n", 
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# d128\n", 
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# d256\n", 
        "\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# R256\n", 
        "\tfor _ in range(n_resnet):\n", 
        "\t\tg = resnet_block(256, g)\n", 
        "\t# u128\n", 
        "\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# u64\n", 
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tg = Activation('relu')(g)\n", 
        "\t# c7s1-3\n", 
        "\tg = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n", 
        "\tg = InstanceNormalization(axis=-1)(g)\n", 
        "\tout_image = Activation('tanh')(g)\n", 
        "\t# define model\n", 
        "\tmodel = Model(in_image, out_image)\n", 
        "\treturn model\n", 
        "\n", 
        "# define a composite model for updating generators by adversarial and cycle loss\n", 
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n", 
        "\t# ensure the model we're updating is trainable\n", 
        "\tg_model_1.trainable = True\n", 
        "\t# mark discriminator as not trainable\n", 
        "\td_model.trainable = False\n", 
        "\t# mark other generator model as not trainable\n", 
        "\tg_model_2.trainable = False\n", 
        "\t# discriminator element\n", 
        "\tinput_gen = Input(shape=image_shape)\n", 
        "\tgen1_out = g_model_1(input_gen)\n", 
        "\toutput_d = d_model(gen1_out)\n", 
        "\t# identity element\n", 
        "\tinput_id = Input(shape=image_shape)\n", 
        "\toutput_id = g_model_1(input_id)\n", 
        "\t# forward cycle\n", 
        "\toutput_f = g_model_2(gen1_out)\n", 
        "\t# backward cycle\n", 
        "\tgen2_out = g_model_2(input_id)\n", 
        "\toutput_b = g_model_1(gen2_out)\n", 
        "\t# define model graph\n", 
        "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n", 
        "\t# define optimization algorithm configuration\n", 
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n", 
        "\t# compile model with weighting of least squares loss and L1 loss\n", 
        "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n", 
        "\treturn model\n", 
        "\n", 
        "# input shape\n", 
        "image_shape = (256,256,3)\n", 
        "# generator: A -> B\n", 
        "g_model_AtoB = define_generator(image_shape)\n", 
        "# generator: B -> A\n", 
        "g_model_BtoA = define_generator(image_shape)\n", 
        "# discriminator: A -> [real/fake]\n", 
        "d_model_A = define_discriminator(image_shape)\n", 
        "# discriminator: B -> [real/fake]\n", 
        "d_model_B = define_discriminator(image_shape)\n", 
        "# composite: A -> B -> [real/fake, A]\n", 
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n", 
        "# composite: B -> A -> [real/fake, B]\n", 
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}