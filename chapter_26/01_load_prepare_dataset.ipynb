{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## What Is the CycleGAN?\n", 
        "The CycleGAN model was described by Jun-Yan Zhu, et al. in their 2017 paper titled Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. The benefit of the CycleGAN model is that it can be trained without paired\n", 
        "examples. That is, it does not require examples of photographs before and after the translation\n", 
        "in order to train the model, e.g. photos of the same city landscape during the day and at night.\n", 
        "Instead, the model is able to use a collection of photographs from each domain and extract\n", 
        "and harness the underlying style of images in the collection in order to perform the translation.\n", 
        "The paper provides a good description of the models and training process, although the official\n", 
        "Torch implementation was used as the definitive description for each model and training process\n", 
        "and provides the basis for the model implementations described below."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "## How to Prepare the Horses to Zebras Dataset\n", 
        "One of the impressive examples of the CycleGAN in the paper was to transform photographs of\n", 
        "horses to zebras, and the reverse, zebras to horses. The authors of the paper referred to this as\n", 
        "the problem of object transfiguration and it was also demonstrated on photographs of apples\n", 
        "and oranges. In this tutorial, we will develop a CycleGAN from scratch for image-to-image\n", 
        "translation (or object transfiguration) from horses to zebras and the reverse. We will refer to\n", 
        "this dataset as horses2zebra.\n", 
        "\n", 
        "You will see the following directory structure:\n", 
        "horse2zebra\n", 
        "\t- testA\n", 
        "\t- testB\n", 
        "\t- trainA\n", 
        "\t- trainB\n", 
        "\n", 
        "The A category refers to horse and B category refers to zebra, and the dataset is comprised\n", 
        "of train and test elements. We will load all photographs and use them as a training dataset.\n", 
        "The photographs are square with the shape 256 \u00d7 256 and have filenames like n023814602.jpg.\n", 
        "The example below will load all photographs from the train and test folders and create an array\n", 
        "of images for category A and another for category B. Both arrays are then saved to a new file in\n", 
        "compressed NumPy array format."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of preparing the horses and zebra dataset\n", 
        "from os import listdir\n", 
        "from numpy import asarray\n", 
        "from numpy import vstack\n", 
        "from keras.preprocessing.image import img_to_array\n", 
        "from keras.preprocessing.image import load_img\n", 
        "from numpy import savez_compressed\n", 
        "\n", 
        "# load all images in a directory into memory\n", 
        "def load_images(path, size=(256,256)):\n", 
        "\tdata_list = list()\n", 
        "\t# enumerate filenames in directory, assume all are images\n", 
        "\tfor filename in listdir(path):\n", 
        "\t\t# load and resize the image\n", 
        "\t\tpixels = load_img(path + filename, target_size=size)\n", 
        "\t\t# convert to numpy array\n", 
        "\t\tpixels = img_to_array(pixels)\n", 
        "\t\t# store\n", 
        "\t\tdata_list.append(pixels)\n", 
        "\treturn asarray(data_list)\n", 
        "\n", 
        "# dataset path\n", 
        "path = 'horse2zebra/'\n", 
        "# load dataset A\n", 
        "dataA1 = load_images(path + 'trainA/')\n", 
        "dataAB = load_images(path + 'testA/')\n", 
        "dataA = vstack((dataA1, dataAB))\n", 
        "print('Loaded dataA: ', dataA.shape)\n", 
        "# load dataset B\n", 
        "dataB1 = load_images(path + 'trainB/')\n", 
        "dataB2 = load_images(path + 'testB/')\n", 
        "dataB = vstack((dataB1, dataB2))\n", 
        "print('Loaded dataB: ', dataB.shape)\n", 
        "# save as compressed numpy array\n", 
        "filename = 'horse2zebra_256.npz'\n", 
        "savez_compressed(filename, dataA, dataB)\n", 
        "print('Saved dataset: ', filename)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}