{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## Separate Discriminator Models With Shared Weights\n", 
        "Starting with the standard GAN discriminator model, we can update it to create two models\n", 
        "that share feature extraction weights. Specifically, we can define one classifier model that\n", 
        "predicts whether an input image is real or fake, and a second classifier model that predicts the\n", 
        "class of a given model.\n", 
        "\n", 
        "\u277c Binary Classifier Model. Predicts whether the image is real or fake, sigmoid activation\n", 
        "function in the output layer, and optimized using the binary cross-entropy loss function.\n", 
        "\u277c Multiclass Classifier Model. Predicts the class of the image, softmax activation\n", 
        "function in the output layer, and optimized using the categorical cross-entropy loss\n", 
        "function.\n", 
        "\n", 
        "Both models have different output layers but share all feature extraction layers. This means\n", 
        "that updates to one of the classifier models will impact both models. The example below creates\n", 
        "the traditional discriminator model with binary output first, then re-uses the feature extraction\n", 
        "layers and creates a new multiclass prediction model, in this case with 10 classes"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of defining semi-supervised discriminator model\n", 
        "from keras.models import Model\n", 
        "from keras.layers import Input\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers import Flatten\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# define the standalone supervised and unsupervised discriminator models\n", 
        "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n", 
        "\t# image input\n", 
        "\tin_image = Input(shape=in_shape)\n", 
        "\t# downsample\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(in_image)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\t# downsample\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\t# downsample\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\t# flatten feature maps\n", 
        "\tfe = Flatten()(fe)\n", 
        "\t# dropout\n", 
        "\tfe = Dropout(0.4)(fe)\n", 
        "\t# unsupervised output\n", 
        "\td_out_layer = Dense(1, activation='sigmoid')(fe)\n", 
        "\t# define and compile unsupervised discriminator model\n", 
        "\td_model = Model(in_image, d_out_layer)\n", 
        "\td_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n", 
        "\t# supervised output\n", 
        "\tc_out_layer = Dense(n_classes, activation='softmax')(fe)\n", 
        "\t# define and compile supervised discriminator model\n", 
        "\tc_model = Model(in_image, c_out_layer)\n", 
        "\tc_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n", 
        "\treturn d_model, c_model\n", 
        "\n", 
        "# create model\n", 
        "d_model, c_model = define_discriminator()\n", 
        "# plot the model\n", 
        "plot_model(d_model, to_file='discriminator1_plot.png', show_shapes=True, show_layer_names=True)\n", 
        "plot_model(c_model, to_file='discriminator2_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('discriminator1_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('discriminator2_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}