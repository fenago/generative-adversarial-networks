{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## Single Discriminator Model With Multiple Outputs\n", 
        "Another approach to implementing the semi-supervised discriminator model is to have a single\n", 
        "model with multiple output layers. Specifically, this is a single model with one output layer for\n", 
        "the unsupervised task and one output layer for the supervised task. This is like having separate\n", 
        "models for the supervised and unsupervised tasks in that they both share the same feature\n", 
        "extraction layers, except that in this case, each input image always has two output predictions,\n", 
        "specifically a real/fake prediction and a supervised class prediction.\n", 
        "A problem with this approach is that when the model is updated with unlabeled and\n", 
        "generated images, there is no supervised class label. In that case, these images must have an\n", 
        "output label of unknown or fake from the supervised output. This means that an additional\n", 
        "class label is required for the supervised output layer. The example below implements the\n", 
        "multi-output single model approach for the discriminator model in the semi-supervised GAN\n", 
        "architecture. We can see that the model is defined with two output layers and that the output\n", 
        "layer for the supervised task is defined with n classes + 1, in this case 11, making room for\n", 
        "the additional unknown class label. We can also see that the model is compiled to two loss\n", 
        "functions, one for each output layer of the model."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of defining semi-supervised discriminator model\n", 
        "from keras.models import Model\n", 
        "from keras.layers import Input\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers import Flatten\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# define the standalone supervised and unsupervised discriminator models\n", 
        "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n", 
        "\t# image input\n", 
        "\tin_image = Input(shape=in_shape)\n", 
        "\t# downsample\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(in_image)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\t# downsample\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\t# downsample\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\t# flatten feature maps\n", 
        "\tfe = Flatten()(fe)\n", 
        "\t# dropout\n", 
        "\tfe = Dropout(0.4)(fe)\n", 
        "\t# unsupervised output\n", 
        "\td_out_layer = Dense(1, activation='sigmoid')(fe)\n", 
        "\t# supervised output\n", 
        "\tc_out_layer = Dense(n_classes + 1, activation='softmax')(fe)\n", 
        "\t# define and compile supervised discriminator model\n", 
        "\tmodel = Model(in_image, [d_out_layer, c_out_layer])\n", 
        "\tmodel.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n", 
        "\treturn model\n", 
        "\n", 
        "# create model\n", 
        "model = define_discriminator()\n", 
        "# plot the model\n", 
        "plot_model(model, to_file='multioutput_discriminator_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('multioutput_discriminator_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}