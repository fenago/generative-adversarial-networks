{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## How to Define and Use the Generator Model\n", 
        "The generator model is responsible for creating new, fake, but plausible small photographs of\n", 
        "objects. It does this by taking a point from the latent space as input and outputting a square\n", 
        "color image. The latent space is an arbitrarily defined vector space of Gaussian-distributed\n", 
        "values, e.g. 100 dimensions. It has no meaning, but by drawing points from this space randomly\n", 
        "and providing them to the generator model during training, the generator model will assign\n", 
        "meaning to the latent points and, in turn, the latent space, until, at the end of training, the\n", 
        "latent vector space represents a compressed representation of the output space, CIFAR-10\n", 
        "images, that only the generator knows how to turn into plausible CIFAR-10 images.\n", 
        "\u277c Inputs: Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n", 
        "\u277c Outputs: Two-dimensional square color image (3 channels) of 32 \u00d7 32 pixels with pixel\n", 
        "values in [-1,1].\n", 
        "\n", 
        "We don\u2019t have to use a 100 element vector as input; it is a round number and widely used,\n", 
        "but I would expect that 10, 50, or 500 would work just as well. Developing a generator model\n", 
        "requires that we transform a vector from the latent space with, 100 dimensions to a 2D array\n", 
        "with 32 \u00d7 32 \u00d7 3, or 3,072 values. There are a number of ways to achieve this, but there is one\n", 
        "approach that has proven effective on deep convolutional generative adversarial networks. It\n", 
        "involves two main elements. The first is a Dense layer as the first hidden layer that has enough\n", 
        "nodes to represent a low-resolution version of the output image. Specifically, an image half the\n", 
        "size (one quarter the area) of the output image would be 16x16x3, or 768 nodes, and an image\n", 
        "one quarter the size (one eighth the area) would be 8 \u00d7 8 \u00d7 3, or 192 nodes.\n", 
        "\n", 
        "With some experimentation, I have found that a smaller low-resolution version of the image\n", 
        "works better. Therefore, we will use 4\u00d74\u00d73, or 48 nodes. We don\u2019t just want one low-resolution\n", 
        "version of the image; we want many parallel versions or interpretations of the input. This is\n", 
        "a pattern in convolutional neural networks where we have many parallel filters resulting in\n", 
        "multiple parallel activation maps, called feature maps, with different interpretations of the input.\n", 
        "We want the same thing in reverse: many parallel versions of our output with different learned\n", 
        "features that can be collapsed in the output layer into a final image. The model needs space\n", 
        "to invent, create, or generate. Therefore, the first hidden layer, the Dense layer, needs enough\n", 
        "nodes for multiple versions of our output image, such as 256."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of defining and using the generator model\n", 
        "from numpy import zeros\n", 
        "from numpy.random import randn\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Reshape\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Conv2DTranspose\n", 
        "from keras.layers import LeakyReLU\n", 
        "%matplotlib notebook\n", 
        "from matplotlib import pyplot\n", 
        "\n", 
        "# define the standalone generator model\n", 
        "def define_generator(latent_dim):\n", 
        "\tmodel = Sequential()\n", 
        "\t# foundation for 4x4 image\n", 
        "\tn_nodes = 256 * 4 * 4\n", 
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\tmodel.add(Reshape((4, 4, 256)))\n", 
        "\t# upsample to 8x8\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# upsample to 16x16\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# upsample to 32x32\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# output layer\n", 
        "\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n", 
        "\treturn model\n", 
        "\n", 
        "# generate points in latent space as input for the generator\n", 
        "def generate_latent_points(latent_dim, n_samples):\n", 
        "\t# generate points in the latent space\n", 
        "\tx_input = randn(latent_dim * n_samples)\n", 
        "\t# reshape into a batch of inputs for the network\n", 
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n", 
        "\treturn x_input\n", 
        "\n", 
        "# use the generator to generate n fake examples, with class labels\n", 
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n", 
        "\t# generate points in latent space\n", 
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n", 
        "\t# predict outputs\n", 
        "\tX = g_model.predict(x_input)\n", 
        "\t# create 'fake' class labels (0)\n", 
        "\ty = zeros((n_samples, 1))\n", 
        "\treturn X, y\n", 
        "\n", 
        "# size of the latent space\n", 
        "latent_dim = 100\n", 
        "# define the discriminator model\n", 
        "model = define_generator(latent_dim)\n", 
        "# generate samples\n", 
        "n_samples = 49\n", 
        "X, _ = generate_fake_samples(model, latent_dim, n_samples)\n", 
        "# scale pixel values from [-1,1] to [0,1]\n", 
        "X = (X + 1) / 2.0\n", 
        "# plot the generated samples\n", 
        "for i in range(n_samples):\n", 
        "\t# define subplot\n", 
        "\tpyplot.subplot(7, 7, 1 + i)\n", 
        "\t# turn off axis labels\n", 
        "\tpyplot.axis('off')\n", 
        "\t# plot single image\n", 
        "\tpyplot.imshow(X[i])\n", 
        "# show the figure\n", 
        "pyplot.show()"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}