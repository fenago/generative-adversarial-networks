{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## How to Define and Train the Discriminator Model\n", 
        "The first step is to define the discriminator model. The model must take a sample image from\n", 
        "our dataset as input and output a classification prediction as to whether the sample is real or\n", 
        "fake. This is a binary classification problem.\n", 
        "\u277c Inputs: Image with three color channel and 32 \u00d7 32 pixels in size.\n", 
        "\u277c Outputs: Binary classification, likelihood the sample is real (or fake).\n", 
        "\n", 
        "The discriminator model has a normal convolutional layer followed by three convolutional\n", 
        "layers using a stride of 2 \u00d7 2 to downsample the input image. The model has no pooling layers\n", 
        "and a single node in the output layer with the sigmoid activation function to predict whether\n", 
        "the input sample is real or fake. The model is trained to minimize the binary cross-entropy\n", 
        "loss function, appropriate for binary classification. We will use some best practices in defining\n", 
        "the discriminator model, such as the use of LeakyReLU instead of ReLU, using Dropout, and\n", 
        "using the Adam version of stochastic gradient descent with a learning rate of 0.0002 and a\n", 
        "momentum of 0.5. The define discriminator() function below defines the discriminator\n", 
        "model and parametrizes the size of the input image."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of defining the discriminator model\n", 
        "from keras.models import Sequential\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# define the standalone discriminator model\n", 
        "def define_discriminator(in_shape=(32,32,3)):\n", 
        "\tmodel = Sequential()\n", 
        "\t# normal\n", 
        "\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# classifier\n", 
        "\tmodel.add(Flatten())\n", 
        "\tmodel.add(Dropout(0.4))\n", 
        "\tmodel.add(Dense(1, activation='sigmoid'))\n", 
        "\t# compile model\n", 
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n", 
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n", 
        "\treturn model\n", 
        "\n", 
        "# define model\n", 
        "model = define_discriminator()\n", 
        "# summarize the model\n", 
        "model.summary()\n", 
        "# plot the model\n", 
        "plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('discriminator_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "Running the example first summarizes the model architecture, showing the output shape for\n", 
        "each layer. We can see that the aggressive 2 \u00d7 2 stride acts to downsample the input image, first\n", 
        "from 32 \u00d7 32 to 16 \u00d7 16, then to 8 \u00d7 8 and more before the model makes an output prediction.\n", 
        "This pattern is by design as we do not use pooling layers and use the large stride to achieve\n", 
        "a similar downsampling effect. We will see a similar pattern, but in reverse in the generator\n", 
        "model in the next section."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}