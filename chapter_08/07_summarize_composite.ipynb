{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## How to Train the Generator Model\n", 
        "The weights in the generator model are updated based on the performance of the discriminator\n", 
        "model. When the discriminator is good at detecting fake samples, the generator is updated more,\n", 
        "and when the discriminator model is relatively poor or confused when detecting fake samples,\n", 
        "the generator model is updated less. This defines the zero-sum or adversarial relationship\n", 
        "between these two models. There may be many ways to implement this using the Keras API,\n", 
        "but perhaps the simplest approach is to create a new model that combines the generator and\n", 
        "discriminator models.\n", 
        "\n", 
        "Specifically, a new GAN model can be defined that stacks the generator and discriminator\n", 
        "such that the generator receives as input random points in the latent space and generates8.5. How to Train the Generator Model 151\n", 
        "samples that are fed into the discriminator model directly, classified, and the output of this\n", 
        "larger model can be used to update the model weights of the generator. To be clear, we are not\n", 
        "talking about a new third model, just a new logical model that uses the already-defined layers\n", 
        "and weights from the standalone generator and discriminator models. Only the discriminator\n", 
        "is concerned with distinguishing between real and fake examples, therefore the discriminator\n", 
        "model can be trained in a standalone manner on examples of each, as we did in the section on\n", 
        "the discriminator model above.\n", 
        "\n", 
        "The generator model is only concerned with the discriminator\u2019s performance on fake examples.\n", 
        "Therefore, we will mark all of the layers in the discriminator as not trainable when it is part\n", 
        "of the GAN model so that they cannot be updated and overtrained on fake examples. When\n", 
        "training the generator via this logical GAN model, there is one more important change. We\n", 
        "want the discriminator to think that the samples output by the generator are real, not fake.\n", 
        "Therefore, when the generator is trained as part of the GAN model, we will mark the generated\n", 
        "samples as real (class = 1).\n", 
        "\n", 
        "Why would we want to do this? We can imagine that the discriminator will then classify\n", 
        "the generated samples as not real (class = 0) or a low probability of being real (0.3 or 0.5). The\n", 
        "backpropagation process used to update the model weights will see this as a large error and will\n", 
        "update the model weights (i.e. only the weights in the generator) to correct for this error, in\n", 
        "turn making the generator better at generating good fake samples. Let\u2019s make this concrete.\n", 
        "\u277c Inputs: Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n", 
        "\u277c Outputs: Binary classification, likelihood the sample is real (or fake).\n", 
        "\n", 
        "The define gan() function below takes as arguments the already-defined generator and\n", 
        "discriminator models and creates the new, logical third model subsuming these two models.\n", 
        "The weights in the discriminator are marked as not trainable, which only affects the weights as\n", 
        "seen by the GAN model and not the standalone discriminator model. The GAN model then\n", 
        "uses the same binary cross-entropy loss function as the discriminator and the efficient Adam\n", 
        "version of stochastic gradient descent with the learning rate of 0.0002 and momentum of 0.5,\n", 
        "recommended when training deep convolutional GANs."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# demonstrate creating the three models in the gan\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Reshape\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Conv2DTranspose\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.layers import Dropout\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# define the standalone discriminator model\n", 
        "def define_discriminator(in_shape=(32,32,3)):\n", 
        "\tmodel = Sequential()\n", 
        "\t# normal\n", 
        "\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# classifier\n", 
        "\tmodel.add(Flatten())\n", 
        "\tmodel.add(Dropout(0.4))\n", 
        "\tmodel.add(Dense(1, activation='sigmoid'))\n", 
        "\t# compile model\n", 
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n", 
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n", 
        "\treturn model\n", 
        "\n", 
        "# define the standalone generator model\n", 
        "def define_generator(latent_dim):\n", 
        "\tmodel = Sequential()\n", 
        "\t# foundation for 4x4 image\n", 
        "\tn_nodes = 256 * 4 * 4\n", 
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\tmodel.add(Reshape((4, 4, 256)))\n", 
        "\t# upsample to 8x8\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# upsample to 16x16\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# upsample to 32x32\n", 
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# output layer\n", 
        "\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n", 
        "\treturn model\n", 
        "\n", 
        "# define the combined generator and discriminator model, for updating the generator\n", 
        "def define_gan(g_model, d_model):\n", 
        "\t# make weights in the discriminator not trainable\n", 
        "\td_model.trainable = False\n", 
        "\t# connect them\n", 
        "\tmodel = Sequential()\n", 
        "\t# add generator\n", 
        "\tmodel.add(g_model)\n", 
        "\t# add the discriminator\n", 
        "\tmodel.add(d_model)\n", 
        "\t# compile model\n", 
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n", 
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n", 
        "\treturn model\n", 
        "\n", 
        "# size of the latent space\n", 
        "latent_dim = 100\n", 
        "# create the discriminator\n", 
        "d_model = define_discriminator()\n", 
        "# create the generator\n", 
        "g_model = define_generator(latent_dim)\n", 
        "# create the gan\n", 
        "gan_model = define_gan(g_model, d_model)\n", 
        "# summarize gan model\n", 
        "gan_model.summary()\n", 
        "# plot gan model\n", 
        "plot_model(gan_model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('gan_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}