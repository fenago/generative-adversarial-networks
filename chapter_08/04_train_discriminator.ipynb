{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# example of training the discriminator model on real and random cifar10 images\n", 
        "from numpy import ones\n", 
        "from numpy import zeros\n", 
        "from numpy.random import rand\n", 
        "from numpy.random import randint\n", 
        "from keras.datasets.cifar10 import load_data\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers import LeakyReLU\n", 
        "\n", 
        "# define the standalone discriminator model\n", 
        "def define_discriminator(in_shape=(32,32,3)):\n", 
        "\tmodel = Sequential()\n", 
        "\t# normal\n", 
        "\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# downsample\n", 
        "\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n", 
        "\tmodel.add(LeakyReLU(alpha=0.2))\n", 
        "\t# classifier\n", 
        "\tmodel.add(Flatten())\n", 
        "\tmodel.add(Dropout(0.4))\n", 
        "\tmodel.add(Dense(1, activation='sigmoid'))\n", 
        "\t# compile model\n", 
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n", 
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n", 
        "\treturn model\n", 
        "\n", 
        "# load and prepare cifar10 training images\n", 
        "def load_real_samples():\n", 
        "\t# load cifar10 dataset\n", 
        "\t(trainX, _), (_, _) = load_data()\n", 
        "\t# convert from unsigned ints to floats\n", 
        "\tX = trainX.astype('float32')\n", 
        "\t# scale from [0,255] to [-1,1]\n", 
        "\tX = (X - 127.5) / 127.5\n", 
        "\treturn X\n", 
        "\n", 
        "# select real samples\n", 
        "def generate_real_samples(dataset, n_samples):\n", 
        "\t# choose random instances\n", 
        "\tix = randint(0, dataset.shape[0], n_samples)\n", 
        "\t# retrieve selected images\n", 
        "\tX = dataset[ix]\n", 
        "\t# generate 'real' class labels (1)\n", 
        "\ty = ones((n_samples, 1))\n", 
        "\treturn X, y\n", 
        "\n", 
        "# generate n fake samples with class labels\n", 
        "def generate_fake_samples(n_samples):\n", 
        "\t# generate uniform random numbers in [0,1]\n", 
        "\tX = rand(32 * 32 * 3 * n_samples)\n", 
        "\t# update to have the range [-1, 1]\n", 
        "\tX = -1 + X * 2\n", 
        "\t# reshape into a batch of color images\n", 
        "\tX = X.reshape((n_samples, 32, 32, 3))\n", 
        "\t# generate 'fake' class labels (0)\n", 
        "\ty = zeros((n_samples, 1))\n", 
        "\treturn X, y\n", 
        "\n", 
        "# train the discriminator model\n", 
        "def train_discriminator(model, dataset, n_iter=20, n_batch=128):\n", 
        "\thalf_batch = int(n_batch / 2)\n", 
        "\t# manually enumerate epochs\n", 
        "\tfor i in range(n_iter):\n", 
        "\t\t# get randomly selected 'real' samples\n", 
        "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n", 
        "\t\t# update discriminator on real samples\n", 
        "\t\t_, real_acc = model.train_on_batch(X_real, y_real)\n", 
        "\t\t# generate 'fake' examples\n", 
        "\t\tX_fake, y_fake = generate_fake_samples(half_batch)\n", 
        "\t\t# update discriminator on fake samples\n", 
        "\t\t_, fake_acc = model.train_on_batch(X_fake, y_fake)\n", 
        "\t\t# summarize performance\n", 
        "\t\tprint('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n", 
        "\n", 
        "# define the discriminator model\n", 
        "model = define_discriminator()\n", 
        "# load image data\n", 
        "dataset = load_real_samples()\n", 
        "# fit the model\n", 
        "train_discriminator(model, dataset)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}