{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "## AC-GAN Discriminator Model\n", 
        "Let\u2019s start with the discriminator model. The discriminator model must take as input an\n", 
        "image and predict both the probability of the realness of the image and the probability of the\n", 
        "image belonging to each of the given classes. The input images will have the shape 28 \u00d7 28 \u00d7 1\n", 
        "and there are 10 classes for the items of clothing in the Fashion-MNIST dataset. The model\n", 
        "can be defined as per the DCGAN architecture. That is, using Gaussian weight initialization,\n", 
        "BatchNormalization, LeakyReLU, Dropout, and a 2 \u00d7 2 stride for downsampling instead of\n", 
        "pooling layers. For example, below is the bulk of the discriminator model defined using the\n", 
        "Keras functional API."
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "The model must be trained with two loss functions, binary cross-entropy for the first output\n", 
        "layer, and categorical cross-entropy loss for the second output layer. Rather than comparing a\n", 
        "one hot encoding of the class labels to the second output layer, as we might do normally, we can\n", 
        "compare the integer class labels directly. We can achieve this automatically using the sparse\n", 
        "categorical cross-entropy loss function. This will have the identical effect of the categorical\n", 
        "cross-entropy but avoids the step of having to manually one hot encode the target labels. When\n", 
        "compiling the model, we can inform Keras to use the two different loss functions for the two\n", 
        "output layers by specifying a list of function names as strings"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "# example of defining the discriminator model\n", 
        "from keras.models import Model\n", 
        "from keras.layers import Input\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import Conv2D\n", 
        "from keras.layers import LeakyReLU\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers import BatchNormalization\n", 
        "from keras.initializers import RandomNormal\n", 
        "from keras.optimizers import Adam\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "\n", 
        "# define the standalone discriminator model\n", 
        "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n", 
        "\t# weight initialization\n", 
        "\tinit = RandomNormal(stddev=0.02)\n", 
        "\t# image input\n", 
        "\tin_image = Input(shape=in_shape)\n", 
        "\t# downsample to 14x14\n", 
        "\tfe = Conv2D(32, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\tfe = Dropout(0.5)(fe)\n", 
        "\t# normal\n", 
        "\tfe = Conv2D(64, (3,3), padding='same', kernel_initializer=init)(fe)\n", 
        "\tfe = BatchNormalization()(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\tfe = Dropout(0.5)(fe)\n", 
        "\t# downsample to 7x7\n", 
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n", 
        "\tfe = BatchNormalization()(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\tfe = Dropout(0.5)(fe)\n", 
        "\t# normal\n", 
        "\tfe = Conv2D(256, (3,3), padding='same', kernel_initializer=init)(fe)\n", 
        "\tfe = BatchNormalization()(fe)\n", 
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n", 
        "\tfe = Dropout(0.5)(fe)\n", 
        "\t# flatten feature maps\n", 
        "\tfe = Flatten()(fe)\n", 
        "\t# real/fake output\n", 
        "\tout1 = Dense(1, activation='sigmoid')(fe)\n", 
        "\t# class label output\n", 
        "\tout2 = Dense(n_classes, activation='softmax')(fe)\n", 
        "\t# define model\n", 
        "\tmodel = Model(in_image, [out1, out2])\n", 
        "\t# compile model\n", 
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n", 
        "\tmodel.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n", 
        "\treturn model\n", 
        "\n", 
        "# define the discriminator model\n", 
        "model = define_discriminator()\n", 
        "# summarize the model\n", 
        "model.summary()\n", 
        "# plot the model\n", 
        "plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }, 
    {
      "source": [
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "image = Image.open('discriminator_plot.png')\n", 
        "display(image)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}